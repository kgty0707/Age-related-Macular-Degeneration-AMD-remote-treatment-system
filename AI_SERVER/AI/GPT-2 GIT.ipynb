{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481d89d6-5abd-4fe9-803e-dcfd1443a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f7fc3c-3a4c-45d1-abe3-7f5d59812062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(s):\n",
    "    s = str(s)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\W,\\s',' ',s)\n",
    "    s = re.sub(\"\\d+\", \"\", s)\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    s = re.sub('[!@#$_]', '', s)\n",
    "    s = s.replace(\"co\",\"\")\n",
    "    s = s.replace(\"https\",\"\")\n",
    "    s = s.replace(\"[\\w*\",\" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22832fdd-eb64-46bd-aebe-f91916a7da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Articles.csv\", encoding=\"ISO-8859-1\") \n",
    "df = df.dropna()\n",
    "text_data = open('Articles.txt', 'w', encoding='utf-8')\n",
    "for idx, item in df.iterrows():\n",
    "  article = cleaning(item[\"Article\"])\n",
    "  text_data.write(article)\n",
    "text_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab292b5-52e9-4b87-b3a3-48fae76d8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb42cb94-402e-48e6-a295-c54adb225770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator\n",
    "\n",
    "\n",
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b498cb7-da21-41dc-8e1e-e193fddebcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"./LLM/Articles.txt\"\n",
    "model_name = 'gpt2'\n",
    "output_dir = './LLM/result'\n",
    "overwrite_output_dir = False\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 5.0\n",
    "save_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad68ac0-0bf9-4a2a-a30d-e6a068ffb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgty\\anaconda3\\envs\\gpu\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5015' max='5015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5015/5015 15:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.124100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.866400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.839600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.789900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.784600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987a7a4-6d8e-4df8-b29f-4181bc148644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afa9cc-a6e4-4768-9477-55966e17401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f697385-7005-4844-80bd-cadcdf93024f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb11d85-e828-4eb0-98d0-0ea6d908b67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5de61c-e37b-46d7-ac16-a1db434a8488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeca9d4-72e9-4484-9966-0d45bead52e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda5dcf-47b2-47f7-955d-ca71f6e59026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3452e-0861-451a-b6de-2acdda36c08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a48e0f43-fdf5-4ab5-a6e8-d1984d9afd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a97ceb-3557-4158-afa5-c57a8def21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def generate_text(sequence, max_length):\n",
    "    model_path = \"./LLM/result\"\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddf1cb-1d30-46b9-bff9-b02084c7d8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44e4ea-97ae-4d24-b9c4-8856c0ed7142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f2dcb-4eaa-468a-9a2d-4a6e59f05c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1be3d-bf5d-49f1-a049-5ee637635635",
   "metadata": {},
   "outputs": [],
   "source": [
    "150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80867039-2268-456e-b192-886eb8070e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9c0f9-44de-462e-b1e4-d2dba319dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77d0a6-6c7a-43f8-a424-51015ad1a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "i want to go cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffa08d-c232-470f-9c5c-5bb49f8b5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "Translate to Korean: A large language model(LLM) is a language model notable for its ability to achieve general-purpose language generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d059e-5add-4e65-852a-d32af4272a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758d694-9df5-4d66-ae8d-d5654341421c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70088449-5b95-4b41-92ba-09acafe4d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6270223e-a7eb-482a-9e98-b1bab7fb9110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " i want to go cafe\n",
      " 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to go cafe until mrd the next session.For all the latest India News, download Indian Express App here.Like Us On Facebook:\n"
     ]
    }
   ],
   "source": [
    "sequence = input() # oil price\n",
    "max_len = int(input()) # 20\n",
    "generate_text(sequence, max_len) # oil price for July June which had been low at as low as was originally stated Prices have since resumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2b83c-78ea-4e6b-a4a2-2d4e36347086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83eb6f8-949f-4e50-ba57-181032d813f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b6425-8261-4b1b-97a3-1b8ee8a55cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1405d-a8cc-43dd-b0ee-fd088c5a949b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
